{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c607100-c012-4d3e-a1be-d648eeecb464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: streamlit in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (1.28.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (5.1.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (8.1.6)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (6.8.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (1.23.5)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (4.23.2)\n",
      "Requirement already satisfied: pyarrow>=6.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (14.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (13.7.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (4.9.0)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (3.1.40)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (6.3.2)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.27->streamlit) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.27->streamlit) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.27->streamlit) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.27->streamlit) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d3b096-f63e-474e-af02-a8c3dd22b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8e1b94-f5d4-4a7c-a477-65e34e771ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dheeraj\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd4b4ae-8c9b-4d8f-8989-c3acf1af65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aade7946-0c0a-4135-9821-8fc753a2feac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dheeraj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#LIBRARIES\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import  PorterStemmer \n",
    "import re\n",
    "\n",
    "\n",
    "#LOAD PICKLE FILES\n",
    "model = pickle.load(open('data and pickle files/best_model.pkl','rb')) \n",
    "vectorizer = pickle.load(open('data and pickle files/count_vectorizer.pkl','rb')) \n",
    "\n",
    "#FOR STREAMLIT\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#TEXT PREPROCESSING\n",
    "sw = set(stopwords.words('english'))\n",
    "def text_preprocessing(text):\n",
    "    txt = TextBlob(text)\n",
    "    result = txt.correct()\n",
    "    removed_special_characters = re.sub(\"[^a-zA-Z]\", \" \", str(result))\n",
    "    tokens = removed_special_characters.lower().split()\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    cleaned = []\n",
    "    stemmed = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in sw:\n",
    "            cleaned.append(token)\n",
    "            \n",
    "    for token in cleaned:\n",
    "        token = stemmer.stem(token)\n",
    "        stemmed.append(token)\n",
    "\n",
    "    return \" \".join(stemmed)\n",
    "\n",
    "#TEXT CLASSIFICATION\n",
    "def text_classification(text):\n",
    "    if len(text) < 1:\n",
    "        st.write(\"  \")\n",
    "    else:\n",
    "        with st.spinner(\"Classification in progress...\"):\n",
    "            cleaned_review = text_preprocessing(text)\n",
    "            process = vectorizer.transform([cleaned_review]).toarray()\n",
    "            prediction = model.predict(process)\n",
    "            p = ''.join(str(i) for i in prediction)\n",
    "        \n",
    "            if p == 'True':\n",
    "                st.success(\"The review entered is Legitimate.\")\n",
    "            if p == 'False':\n",
    "                st.error(\"The review entered is Fraudulent.\")\n",
    "\n",
    "#PAGE FORMATTING AND APPLICATION\n",
    "def main():\n",
    "    st.title(\"Fraud Detection in Online Consumer Reviews Using Machine Learning Techniques\")\n",
    "    \n",
    "    \n",
    "    # --EXPANDERS--    \n",
    "    abstract = st.expander(\"Abstract\")\n",
    "    if abstract:\n",
    "        abstract.write(\"In today's world, both businesses and customers believe reviews to be quite beneficial. It's no surprise that review fraud has devalued the whole experience, from nasty reviews putting harm to the business's credibility to breaking international laws. This has been seen as a developing problem, and because it is related to natural language processing, it was critical to develop various machine learning methodologies and techniques to achieve a breakthrough in this sector. Many e-commerce sites, such as Amazon, have their systems in place, including Verified Purchase, which labels review language as accurate when items are purchased directly from the website. This work proposes to use Amazon's verified purchases label to train three classifiers for supervised training on Amazon’s labelled dataset. MNB, SVM, and LR were chosen as classifiers, and model tuning was done using two distinct vectorizers, Count Vectorizer and TF-IDF Vectorizers. Overall, all of the trained models had an accuracy rate of 80%, indicating that the vectorizers functioned admirably and that there are distinctions between false and actual reviews. Out of the two, the count vectorizer improved the models' performance more, and out of the three inside counts, LR performed the best, with an accuracy rate of 85% and a recall rate of 92%. The LR classifier was used, and it was accessible to the public to see if the reviews entered were genuine or not, with a probability score.\")\n",
    "        #st.write(abstract)\n",
    "    \n",
    "    links = st.expander(\"Related Links\")\n",
    "    if links:\n",
    "        links.write(\"[Dataset utilized](https://www.kaggle.com/akudnaver/amazon-reviews-dataset)\")\n",
    "        links.write(\"[Github](https://github.com/kntb0107/Fraud-Detection-in-Online-Consumer-Reviews-Using-Machine-Learning-Techniques)\")\n",
    "        \n",
    "    # --CHECKBOXES--\n",
    "    st.subheader(\"Information on the Classifier\")\n",
    "    if st.checkbox(\"About Classifer\"):\n",
    "        st.markdown('**Model:** Logistic Regression')\n",
    "        st.markdown('**Vectorizer:** Count')\n",
    "        st.markdown('**Test-Train splitting:** 40% - 60%')\n",
    "        st.markdown('**Spelling Correction Library:** TextBlob')\n",
    "        st.markdown('**Stemmer:** PorterStemmer')\n",
    "        \n",
    "    if st.checkbox(\"Evaluation Results\"):\n",
    "        st.markdown('**Accuracy:** 85%')\n",
    "        st.markdown('**Precision:** 80%')\n",
    "        st.markdown('**Recall:** 92%')\n",
    "        st.markdown('**F-1 Score:** 85%')\n",
    "\n",
    "\n",
    "    #--IMPLEMENTATION OF THE CLASSIFIER--\n",
    "    st.subheader(\"Fake Review Classifier\")\n",
    "    review = st.text_area(\"Enter Review: \")\n",
    "    if st.button(\"Check\"):\n",
    "        text_classification(review)\n",
    "\n",
    "#RUN MAIN        \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64eea5b-7e3e-4ae9-b1bb-c5f73add1e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af54674-0991-47fa-8edd-8205c4c5374b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
